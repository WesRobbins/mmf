optimizer:
  params:
    eps: 1.0e-08
    lr: 1e-4
    weight_decay: 0
  type: Adam

multitasking:
  enabled: true
  type: constant #ratios
  params: {}
 # params:
 #   sampling_ratios:
 #     pac: 1
 #     textcaps: 1


dataset_config:
  pac:
    data_dir: /content/drive/MyDrive/data/mmf
    depth_first: false
    fast_read: false
    zoo_requirements:
    - textcaps.defaults
    - textvqa.defaults
    max_features: 100
    use_images: false
    use_features: true
    use_order_vectors: true
    # annotation_style can be coco or textcaps which allows us to override
    # the dataset class
    annotation_style: textcaps
    features:
     train:
      - /content/drive/MyDrive/NEW_DATASET/lmdbs/splits/split0/obj.lmdb/train.lmdb,/content/drive/MyDrive/NEW_DATASET/lmdbs/splits/split0/ocr.lmdb/train.lmdb
     val:
      - /content/drive/MyDrive/NEW_DATASET/lmdbs/splits/split0/obj.lmdb/test.lmdb,/content/drive/MyDrive/NEW_DATASET/lmdbs/splits/split0/ocr.lmdb/test.lmdb
     test:
      - /content/drive/MyDrive/NEW_DATASET/lmdbs/splits/split0/obj.lmdb/test.lmdb,/content/drive/MyDrive/NEW_DATASET/lmdbs/splits/split0/ocr.lmdb/test.lmdb
    annotations:
      train:
      - /content/drive/MyDrive/NEW_DATASET/npys/annotations/splits/split0/train/oh_annotations.npy
      val:
      - /content/drive/MyDrive/NEW_DATASET/npys/annotations/splits/split0/test/oh_annotations.npy
      test:
      - /content/drive/MyDrive/NEW_DATASET/npys/annotations/splits/split0/test/oh_annotations.npy

    processors:
      text_processor:
        type: bert_tokenizer
        params:
          tokenizer_config:
            type: bert-base-uncased
            params:
              do_lower_case: true
          max_seq_length: 3
      answer_processor:
        type: m4c_caption
        params:
          vocab_file: /content/drive/MyDrive/data/mmf/datasets/textcaps/defaults/extras/vocabs/vocab_textcaps_threshold_10_new.txt
          preprocessor:
            type: simple_word
            params: {}
          context_preprocessor:
            type: simple_word
            params: {}
          max_length: 50
          max_copy_steps: 30
          num_answers: 1
      copy_processor:
        type: copy
        params:
          max_length: 100
      phoc_processor:
        type: phoc
        params:
          max_length: 50
      context_processor:
        type: fasttext
        params:
          max_length: 50
          model_file: wiki.en.bin
      ocr_token_processor:
        type: simple_word
        params: {}
      bbox_processor:
        type: bbox
        params:
          max_length: 50
    return_features_info: true
    use_ocr: true
    use_ocr_info: true
  textcaps:
    data_dir: ${env.data_dir}/datasets
    depth_first: false
    fast_read: false
    zoo_requirements:
    - textcaps.defaults
    - textvqa.defaults
    max_features: 100
    use_images: false
    use_features: true
    use_order_vectors: true
    # annotation_style can be coco or textcaps which allows us to override
    # the dataset class
    annotation_style: textcaps
    features:
      train:
      - textvqa/defaults/features/open_images/detectron.lmdb,textvqa/ocr_en/features/ocr_en_frcn_features.lmdb
      val:
      - textvqa/defaults/features/open_images/detectron.lmdb,textvqa/ocr_en/features/ocr_en_frcn_features.lmdb
      test:
      - textvqa/defaults/features/open_images/detectron.lmdb,textvqa/ocr_en/features/ocr_en_frcn_features.lmdb
    annotations:
      train:
      - textcaps/defaults/annotations/oh_imdb_train.npy
      val:
      - textcaps/defaults/annotations/oh_imdb_val_filtered_by_image_id.npy  # only one sample per image_id
      test:
      - textcaps/defaults/annotations/imdb_test_filtered_by_image_id.npy  # only one sample per image_id
    processors:
      text_processor:
        type: bert_tokenizer
        params:
          tokenizer_config:
            type: bert-base-uncased
            params:
              do_lower_case: true
          max_seq_length: 3
      answer_processor:
        type: m4c_caption
        params:
          vocab_file: textcaps/defaults/extras/vocabs/vocab_textcaps_threshold_10_new.txt
          preprocessor:
            type: simple_word
            params: {}
          context_preprocessor:
            type: simple_word
            params: {}
          max_length: 50
          max_copy_steps: 30
          num_answers: 1
      copy_processor:
        type: copy
        params:
          max_length: 100
      phoc_processor:
        type: phoc
        params:
          max_length: 50
      context_processor:
        type: fasttext
        params:
          max_length: 50
          model_file: wiki.en.bin
      ocr_token_processor:
        type: simple_word
        params: {}
      bbox_processor:
        type: bbox
        params:
          max_length: 50
    return_features_info: true
    use_ocr: true
    use_ocr_info: true
     
evaluation:
  metrics:
  - textcaps_bleu4

model_config:
  spec_captioner:
    lr_scale_frcn: 0.1
    lr_scale_text_bert: 0.1
    lr_scale_mmt: 1.0
    text_bert_init_from_bert_base: true
    text_bert:
      num_hidden_layers: 3
    obj:
      mmt_in_dim: 2048
      dropout_prob: 0.1
    ocr:
      mmt_in_dim: 3002
      dropout_prob: 0.1
    mmt:
      hidden_size: 768
      num_hidden_layers: 4
    classifier:
      type: linear
      ocr_max_num: 50
      ocr_ptr_net:
        hidden_size: 768
        query_key_size: 768
      params: {}
    model_data_dir: /content/drive/MyDrive/data/mmf/
    losses:
    - type: m4c_decoding_bce_with_mask
    remove_unk_in_pred: true
    model: spec_captioner
    
training:
    clip_norm_mode: all
    clip_gradients: true
    max_grad_l2_norm: 0.25
    lr_scheduler: true
    lr_steps:
    - 10000
    - 11000
    lr_ratio: 0.1
    use_warmup: true
    warmup_factor: 0.2
    warmup_iterations: 1000
    max_iterations: 12000
    batch_size: 8
    num_workers: 1
    task_size_proportional_sampling: true
    early_stop:
      criteria: textcaps/textcaps_bleu4
      minimize: false
